{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3132ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 - Training and Evaluation of LightGCN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.utils import degree\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "import gc\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb95362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5582, 64], edge_index=[2, 95220], num_nodes=5582, num_users=3404, num_books=2178)\n"
     ]
    }
   ],
   "source": [
    "## 1. Load Graph\n",
    "\n",
    "from torch_geometric.data.data import DataTensorAttr, DataEdgeAttr\n",
    "from torch_geometric.data.storage import GlobalStorage\n",
    "import torch.serialization\n",
    "\n",
    "torch.serialization.add_safe_globals([DataTensorAttr, DataEdgeAttr, GlobalStorage])\n",
    "\n",
    "data = torch.load('data/processed/graph_data.pt')\n",
    "num_users = data.num_users\n",
    "num_books = data.num_books\n",
    "num_nodes = data.num_nodes\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "644aaf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading splits...\n",
      "Positive edges - Train: 38088, Val: 4761, Test: 4761\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "required_files = [\n",
    "    'data/processed/train_edge_index.pt',\n",
    "    'data/processed/train_pos.pt',\n",
    "    'data/processed/val_pos.pt',\n",
    "    'data/processed/test_pos.pt'\n",
    "]\n",
    "\n",
    "def create_splits():\n",
    "    print(\"Creating reproducible split...\")\n",
    "    # Ensure user → book direction for positive edges\n",
    "    user_to_book = data.edge_index[:, data.edge_index[0] < num_users]  # only user → book\n",
    "\n",
    "    num_pos = user_to_book.size(1)\n",
    "    perm = torch.randperm(num_pos, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    train_size = int(0.8 * num_pos)\n",
    "    val_size = int(0.1 * num_pos)\n",
    "\n",
    "    train_pos = user_to_book[:, perm[:train_size]]\n",
    "    val_pos = user_to_book[:, perm[train_size:train_size+val_size]]\n",
    "    test_pos = user_to_book[:, perm[train_size+val_size:]]\n",
    "\n",
    "    # Build full undirected graphs for propagation\n",
    "    def make_undirected(pos_edges):\n",
    "        rev = torch.stack([pos_edges[1], pos_edges[0]])\n",
    "        return torch.cat([pos_edges, rev], dim=1)\n",
    "\n",
    "    train_edge_index = make_undirected(train_pos)\n",
    "    val_edge_index = make_undirected(val_pos)   # not used for prop\n",
    "    test_edge_index = make_undirected(test_pos)\n",
    "\n",
    "    # Save only the positive directions for evaluation\n",
    "    torch.save(train_pos, 'data/processed/train_pos.pt')\n",
    "    torch.save(val_pos, 'data/processed/val_pos.pt')\n",
    "    torch.save(test_pos, 'data/processed/test_pos.pt')\n",
    "    torch.save(train_edge_index, 'data/processed/train_edge_index.pt')\n",
    "\n",
    "    print(f\"Saved splits: Train {train_pos.size(1)}, Val {val_pos.size(1)}, Test {test_pos.size(1)}\")\n",
    "    return train_pos, val_pos, test_pos, train_edge_index\n",
    "\n",
    "# Create splits if any required file is missing, else try to load (fall back to recreate on error)\n",
    "if not all(os.path.exists(f) for f in required_files):\n",
    "    train_pos, val_pos, test_pos, train_edge_index = create_splits()\n",
    "else:\n",
    "    try:\n",
    "        print(\"Loading splits...\")\n",
    "        train_pos = torch.load('data/processed/train_pos.pt')\n",
    "        val_pos = torch.load('data/processed/val_pos.pt')\n",
    "        test_pos = torch.load('data/processed/test_pos.pt')\n",
    "        train_edge_index = torch.load('data/processed/train_edge_index.pt')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading splits ({e}), recreating...\")\n",
    "        train_pos, val_pos, test_pos, train_edge_index = create_splits()\n",
    "\n",
    "print(f\"Positive edges - Train: {train_pos.size(1)}, Val: {val_pos.size(1)}, Test: {test_pos.size(1)}\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b287c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGCN(\n",
      "  (user_embedding): Embedding(3404, 64)\n",
      "  (item_embedding): Embedding(2178, 64)\n",
      ")\n",
      "Parameters: 357,248\n"
     ]
    }
   ],
   "source": [
    "## 3. LightGCN Model\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_books, embedding_dim=64, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_books = num_books\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_books, embedding_dim)\n",
    "        \n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "    \n",
    "    def forward(self, edge_index):\n",
    "        x = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)\n",
    "        \n",
    "        out_list = [x]\n",
    "        for _ in range(self.num_layers):\n",
    "            x = self.propagate(x, edge_index)\n",
    "            out_list.append(x)\n",
    "        \n",
    "        final = sum(out_list) / (self.num_layers + 1)\n",
    "        user_emb, item_emb = torch.split(final, [self.num_users, self.num_books])\n",
    "        return user_emb, item_emb\n",
    "    \n",
    "    def propagate(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, num_nodes=x.size(0))\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        \n",
    "        # Sparse multiplication\n",
    "        edge_index_sparse = torch.sparse_coo_tensor(edge_index, norm, (x.size(0), x.size(0)))\n",
    "        return edge_index_sparse @ x\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = LightGCN(num_users, num_books, embedding_dim=64, num_layers=3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "print(model)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17d09873",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. BPR Loss and Training Epoch\n",
    "\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    return -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_embeddings(model, edge_index):\n",
    "    model.eval()\n",
    "    return model(edge_index)\n",
    "\n",
    "def train_epoch(model, edge_index, batch_size=2048):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Use positive direction only for batching\n",
    "    pos_edges = edge_index[:, ::2]  # one direction\n",
    "    perm = torch.randperm(pos_edges.size(1))\n",
    "    pos_edges = pos_edges[:, perm]\n",
    "    \n",
    "    for start in range(0, pos_edges.size(1), batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_pos = pos_edges[:, start:end]\n",
    "        \n",
    "        # Random negative items (same number)\n",
    "        neg_items = torch.randint(0, num_books, (batch_pos.size(1),), device=device)\n",
    "        \n",
    "        # Full forward (on whole graph - efficient for small data)\n",
    "        user_emb, item_emb = get_embeddings(model, edge_index)\n",
    "        \n",
    "        # Scores\n",
    "        pos_u_emb = user_emb[batch_pos[0]]\n",
    "        pos_i_emb = item_emb[batch_pos[1] - num_users]\n",
    "        neg_i_emb = item_emb[neg_items]\n",
    "        \n",
    "        pos_scores = (pos_u_emb * pos_i_emb).sum(dim=1)\n",
    "        neg_scores = (pos_u_emb * neg_i_emb).sum(dim=1)\n",
    "        \n",
    "        loss = bpr_loss(pos_scores, neg_scores)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # stability\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / (pos_edges.size(1) // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aaa05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Evaluation (Fixed)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, pos_edges, K=10):\n",
    "    model.eval()\n",
    "    user_emb, item_emb = model(train_edge_index)\n",
    "    scores = user_emb @ item_emb.t()  # [num_users, num_books]\n",
    "    \n",
    "    # Mask training positives\n",
    "    mask = torch.zeros(num_users, num_books, dtype=torch.bool)\n",
    "    mask[train_pos[0], train_pos[1] - num_users] = True\n",
    "    scores[mask] = -1e8\n",
    "    \n",
    "    _, topk = torch.topk(scores, K, dim=1)\n",
    "    \n",
    "    users = pos_edges[0].cpu()\n",
    "    true_items = pos_edges[1].cpu() - num_users\n",
    "    \n",
    "    recall = 0.0\n",
    "    ndcg = 0.0\n",
    "    num_users_with_test = users.unique().size(0)\n",
    "    \n",
    "    for u in users.unique():\n",
    "        u_topk = topk[u]\n",
    "        u_true = true_items[users == u]\n",
    "        hits = torch.isin(u_topk, u_true)\n",
    "        if hits.any():\n",
    "            recall += 1\n",
    "            rank = hits.nonzero(as_tuple=True)[0][0] + 1\n",
    "            ndcg += 1 / np.log2(rank + 1)\n",
    "    \n",
    "    return recall / num_users_with_test, ndcg / len(pos_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45200e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, edge_index, batch_size=2048, pos_edges=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # Use provided pos_edges if available, otherwise fall back to slicing\n",
    "    if pos_edges is None:\n",
    "        pos_edges = edge_index[:, ::2]  # one direction if not provided\n",
    "\n",
    "    pos_edges = pos_edges.to(edge_index.device)\n",
    "    perm = torch.randperm(pos_edges.size(1))\n",
    "    pos_edges = pos_edges[:, perm]\n",
    "\n",
    "    for start in range(0, pos_edges.size(1), batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_pos = pos_edges[:, start:end]\n",
    "        if batch_pos.size(1) == 0:\n",
    "            continue\n",
    "\n",
    "        # Random negative items\n",
    "        neg_items = torch.randint(0, num_books, (batch_pos.size(1),), device=edge_index.device)\n",
    "\n",
    "        # Forward pass on full training graph\n",
    "        user_emb, item_emb = model(edge_index)\n",
    "\n",
    "        # Positive scores\n",
    "        users = batch_pos[0]\n",
    "        pos_items = batch_pos[1] - num_users\n",
    "        pos_scores = (user_emb[users] * item_emb[pos_items]).sum(dim=1)\n",
    "\n",
    "        # Negative scores\n",
    "        neg_scores = (user_emb[users] * item_emb[neg_items]).sum(dim=1)\n",
    "\n",
    "        # BPR loss\n",
    "        loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return total_loss / num_batches if num_batches > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c10cdeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGCN training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiwi\\AppData\\Local\\Temp\\ipykernel_3680\\3956606463.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  ndcg += 1 / np.log2(rank + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.6930 | Val Recall@10: 0.1177 | Val NDCG@10: 63.0130\n",
      "  >>> Best model saved!\n",
      "Epoch 02 | Loss: 0.6920 | Val Recall@10: 0.1098 | Val NDCG@10: 59.6696\n",
      "Epoch 03 | Loss: 0.6872 | Val Recall@10: 0.1039 | Val NDCG@10: 56.0294\n",
      "Epoch 04 | Loss: 0.6762 | Val Recall@10: 0.0990 | Val NDCG@10: 53.5635\n",
      "Epoch 05 | Loss: 0.6592 | Val Recall@10: 0.0975 | Val NDCG@10: 52.8414\n",
      "Epoch 06 | Loss: 0.6384 | Val Recall@10: 0.0975 | Val NDCG@10: 53.3798\n",
      "Epoch 07 | Loss: 0.6178 | Val Recall@10: 0.0931 | Val NDCG@10: 51.6983\n",
      "Epoch 08 | Loss: 0.5975 | Val Recall@10: 0.0955 | Val NDCG@10: 52.5229\n",
      "Early stopping.\n",
      "\n",
      "Training done!\n",
      "Test Recall@10: 0.1203 | Test NDCG@10: 65.6868\n"
     ]
    }
   ],
   "source": [
    "# 6. Training Loop - This Will Work\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "best_recall = 0.0\n",
    "patience = 7\n",
    "wait = 0\n",
    "max_epochs = 50\n",
    "\n",
    "print(\"Starting LightGCN training...\\n\")\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    loss = train_epoch(model, train_edge_index, pos_edges=train_pos, batch_size=2048)\n",
    "    \n",
    "    val_recall, val_ndcg = evaluate(model, val_pos, K=10)\n",
    "    \n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val Recall@10: {val_recall:.4f} | Val NDCG@10: {val_ndcg:.4f}\")\n",
    "    \n",
    "    if val_recall > best_recall:\n",
    "        best_recall = val_recall\n",
    "        torch.save(model.state_dict(), 'models/best_lightgcn.pt')\n",
    "        wait = 0\n",
    "        print(\"  >>> Best model saved!\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"\\nTraining done!\")\n",
    "model.load_state_dict(torch.load('models/best_lightgcn.pt'))\n",
    "test_recall, test_ndcg = evaluate(model, test_pos, K=10)\n",
    "print(f\"Test Recall@10: {test_recall:.4f} | Test NDCG@10: {test_ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
